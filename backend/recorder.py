import os
import wave
import numpy as np
import sounddevice as sd
from dotenv import load_dotenv
from datetime import datetime
import time

# ä¿®æ­£ï¼šè¼‰å…¥æ­£ç¢ºçš„ .env è·¯å¾‘ï¼ˆå¾ backend/config/.envï¼‰
env_path = os.path.abspath(os.path.join(os.path.dirname(__file__), 'config', '.env'))
load_dotenv(env_path)

class AudioRecorder:
    def __init__(self):
        self.sample_rate = int(os.getenv('SAMPLE_RATE', 16000))
        self.channels = int(os.getenv('CHANNELS', 1))
        self.chunk_duration = 0.5  # æ¯0.5ç§’éŒ„ä¸€å€‹å€å¡Š
        self.silence_threshold = 0.001
        self.silence_duration = 3

        # ä¿®æ­£ï¼šç¢ºä¿ audio_dir æ˜¯çµ•å°è·¯å¾‘
        self.audio_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), 'data', 'audio'))
        os.makedirs(self.audio_dir, exist_ok=True)

    def record(self):
        """é€£çºŒéŒ„éŸ³ç›´åˆ°åµæ¸¬3ç§’ç„¡è²ï¼Œè‡ªå‹•åœæ­¢ï¼Œä¸¦å„²å­˜æˆ WAV æª”"""
        print("ğŸ™ï¸ é–‹å§‹éŒ„éŸ³ï¼Œè«‹é–‹å§‹èªªè©±...")

        recording = []
        last_voice_time = None
        block_size = int(self.sample_rate * self.chunk_duration)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_filename = os.path.join(self.audio_dir, f"recording_{timestamp}.wav")

        while True:
            block = sd.rec(block_size, samplerate=self.sample_rate, channels=self.channels, dtype='float32')
            sd.wait()
            energy = np.linalg.norm(block) / block_size
            recording.append(block)

            if energy > self.silence_threshold:
                last_voice_time = time.time()

            if last_voice_time is not None and (time.time() - last_voice_time > self.silence_duration):
                print("â¹ï¸ åµæ¸¬åˆ°3ç§’ç„¡è²ï¼Œè‡ªå‹•åœæ­¢éŒ„éŸ³")
                break

        recording = np.concatenate(recording, axis=0)

        with wave.open(output_filename, 'wb') as wf:
            wf.setnchannels(self.channels)
            wf.setsampwidth(2)
            wf.setframerate(self.sample_rate)
            wf.writeframes((recording * 32767).astype(np.int16).tobytes())

        print(f"âœ… éŒ„éŸ³å®Œæˆï¼Œå·²å„²å­˜ç‚º {output_filename}")
        return output_filename

    def is_silent(self, audio_data, silence_threshold=500):
        """æª¢æŸ¥æ˜¯å¦æ˜¯éœéŸ³ï¼ˆæ²’è®Šå‹•ï¼‰"""
        return np.mean(np.abs(audio_data)) < silence_threshold

    def wait_for_speech(self):
        """ä¿ç•™åŸæœ¬ wait_for_speechï¼Œä¸è®Š"""
        print("ç­‰å¾…èªéŸ³è¼¸å…¥...")
        while True:
            audio_data = sd.rec(
                int(self.sample_rate * 0.1),
                samplerate=self.sample_rate,
                channels=self.channels,
                dtype=np.int16
            )
            sd.wait()

            if not self.is_silent(audio_data):
                print("æª¢æ¸¬åˆ°èªéŸ³!")
                return True
